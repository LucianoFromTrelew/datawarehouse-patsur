%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% En 'inclues.tex' se encuentran la importación de paquetes necesarios
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{includes}
\input{listings_settings}


\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% En 'titlepage.tex' se encuentra la página de título
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{titlepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% INDICE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\tableofcontents
\clearpage 

\lstset{style=sql}

\section{Introducción}

Para el siguiente trabajo de laboratorio se solicitaba implementar las bases de datos operacionales y un datawarehouse que satisfaga las necesidades de la empresa \dq{PatSur}. Los requerimientos son los siguientes:

\begin{displayquote}\itshape

La cooperativa frutihorticola “PatSur” lleva operando 5 años en la región patagónica. Ha ido creciendo y abriendo sucursales en otras ciudades y participa en la provisión de mercaderías a fabricas, otras cooperativas, pymes, cadenas de supermercados. A medida que fue ampliando su ámbito de compra y venta ha ido modifcando sus sistemas para manejar nuevos datos como producciones, vendedores y compradores, lugares de compra y venta, transportes, empleados, etc. De allí que cada Gerente de área posea distintos datos en diferentes formas. Por lo tanto la primer idea es tener un información de las ventas. 

La empresa cuenta con dos (2) sistemas distintos de facturación de productos (a partir del año 2010 se implementó un sistema desarrollado por una consultora, mientras que antes del 2010 se utilizaba un sistema desarrollado por el sobrino de uno de los socios de la cooperativa).  

\end{displayquote}

Las implementaciones de todos los sistemas necesarios fueron hechas con contenedores de \docker{} y orquestrados con \doccom{}; se deja a disposición con el presente informe y todos los \emph{scripts} utilizados el archivo de configuración para levantar todos los contenedores necesarios. 

Los cuatro servicios creados por contenedores (un contenedor por servicio) se encuentran dentro de la red \textbf{172.40.0.0/16}, cada uno con las siguientes características:
\begin{itemize}
    \item Sistema de facturación viejo:
        \begin{itemize}
            \item Imagen: \underline{\href{https://hub.docker.com/_/postgres/}{PostgreSQL 9.6}}
            \item Dirección IP: 172.40.0.10
            \item Puerto de escucha: 5432
            \item Nombre de la base de datos: facturacion
            \item Usuario: admin
            \item Contraseña: admin
        \end{itemize}
    \item Sistema de facturación actual
        \begin{itemize}
            \item Imagen: \underline{\href{https://hub.docker.com/_/postgres/}{PostgreSQL 9.6}}
            \item Dirección IP: 172.40.0.20
            \item Puerto de escucha: 5432
            \item Nombre de la base de datos: facturacion
            \item Usuario: admin
            \item Contraseña: admin
        \end{itemize}
    \item Datawarehouse:
        \begin{itemize}
            \item Imagen: \underline{\href{https://hub.docker.com/_/postgres/}{PostgreSQL 9.6}}
            \item Dirección IP: 172.40.0.30
            \item Puerto de escucha: 5432
            \item Nombre de la base de datos: datawarehouse
            \item Usuario: admin
            \item Contraseña: admin
        \end{itemize}
    \item Pentaho \emph{BI Server} :
        \begin{itemize}
            \item Imagen: \underline{\href{https://hub.docker.com/r/wmarinho/pentaho/}{Pentaho BI Server}}
            \item Dirección IP: 172.40.0.40
            \item Puerto de escucha: 7070
        \end{itemize}
\end{itemize}

\section{Bases de datos operacionales}

Los sistemas de facturación de \dq{PatSur} presentan distintos modelados de datos, por lo cual la definición de las tablas de las bases de datos y su correspondiente cargado de datos serán procesos distintos.

Todos los \emph{scipts} a los que se haga referencia se encontrarán en el directorio \textbf{\dq{scripts}}. Los \emph{scripts} correspondientes a la carga de datos tanto de los sistemas operacionales como del datawarehouse se encontrarán en el subdirectorio \textbf{\dq{scripts/cargas}}   

\subsection{Sistema viejo}

\subsubsection{Definición}

El primer sistema con el que dispuso la empresa tenía la siguiente estructura de tablas:

\begin{itemize}
    \item Cliente(\textbf{nro\_cliente}, nombre, tipo, direccion)
    \item Categoria(\textbf{nro\_categ}, descripcion)
    \item Venta(\textbf{nro\_factura}, fecha\_venta, \underline{nro\_cliente}, nombre, forma\_pago)
    \item Detalle\_Venta(\underline{\textbf{nro\_factura}}, \underline{\textbf{nro\_producto}}, descripcion, unidad, precio)
    \item Producto(\textbf{nro\_producto}, nombre, \underline{nro\_categ}, precio\_actual)
\end{itemize}

El \emph{script} correspondiente para la definición de las tablas previamente definidas tiene el nombre \textbf{tablas\_sistema\_viejo.sql} 

\subsubsection{Poblado}

\emph{Los siguientes \emph{scripts} mencionados se encuentran en el subdirectorio \dq{scripts/cargas/sistema\_viejo} y en \dq{scripts/cargas/sistema\_viejo/sql}} 

~\\

A través de \emph{scripts} escritos en Python (\textbf{productos.py} y \textbf{categorias.py}), se pudieron extraer datos de la \emph{API} de MercadoLibre \autocite{api} para disponer de datos con cierto grado de veracidad. Estos \emph{scripts} se encargan de consultar la fuente de datos, y de armar \emph{scripts} en SQL (\textbf{sql/productos} y \textbf{categorias.sql}) para la inserción en la tabla correspondiente (adecuando los datos acordemente al modelo de la base de datos)  

MercadoLibre maneja un árbol de \textbf{categorías} muy amplio y con muchas ramas, de las cuales solamente se exploraron y utilizaron unas pocas para este trabajo. También se obtuvieron \textbf{productos} de dichas categorías

\vspace*{5mm}
\begin{lstlisting}[title=Cantidad de categorías y productos disponibles en el sistema de facturación viejo]
facturacion=# SELECT COUNT(*) FROM categoria;
 count 
-------
    30
(1 row)

facturacion=# SELECT COUNT(*) FROM producto;
 count 
-------
  1450
(1 row)
\end{lstlisting}

Con respecto a los \textbf{clientes}, se utilizó un sitio generador de datos \autocite{data} para crear registros de clientes ficticios (\textbf{sql/clientes.sql}). 

Por último, los archivos \textbf{sql/venta.sql} y \textbf{sql/detalle\_venta.sql} contienen las definiciones de las funciones \textbf{insertar\_venta(int)} e \textbf{insertar\_detalle\_venta(int)}. Ambas funciones reciben un valor entero como parámetro, que indica la cantidad de registros que se quieren crear (tomando valores aleatorios de la base). Estas funciones son acumulativas, entonces se pueden correr cuantas veces se desee para poblar las tablas de ventas y detalles de ventas.

\vspace*{5mm}
\begin{lstlisting}[title=Inserción de 50 ventas aleatorias en la BD]
facturacion=# SELECT insertar_ventas(50);
NOTICE:  [1/50] INSERTANDO VENTA (2007-10-03, 862512, 4118, Linda Acosta, EFECTIVO)
NOTICE:  [2/50] INSERTANDO VENTA (2002-07-29, 143370, 3458, Jeremy Pacheco, CREDITO)
NOTICE:  [3/50] INSERTANDO VENTA (2006-02-15, 993978, 2414, Lisandra Bernard, DEBITO)
...
\end{lstlisting}

\vspace*{5mm}
\begin{lstlisting}[title=Inserción de 300 detalles de ventas aleatorias en la BD]
facturacion=# SELECT insertar_detalle_venta(300);
NOTICE:  [1/300] INSERTANDO DETALLE (333538, 639930615, 19, 169.99)
NOTICE:  [2/300] INSERTANDO DETALLE (743695, 644739590, 41, 72)
NOTICE:  [3/300] INSERTANDO DETALLE (124334, 712205536, 54, 419500)
...
\end{lstlisting}

\subsection{Sistema actual}

\subsubsection{Definición}

El sistema desarrollado en el 2010 por la consultora cuenta con el siguiente esquema:

\begin{itemize}
    \item Cliente(\textbf{cod\_cliente}, nombre, \underline{cod\_tipo}, direccion)
    \item Tipo\_Cliente(\textbf{cod\_tipo}, descripcion)
    \item Producto(\textbf{cod\_producto}, nombre, \underline{cod\_categoria}, \underline{cod\_subcategoria}, precio\_actual)
    \item Categoria(\textbf{cod\_categoria}, \textbf{cod\_subcategoria}, descripcion)
    \item Venta(\textbf{id\_factura}, fecha\_venta, \underline{cod\_cliente}, nombre, \underline{cod\_medio\_pago})
    \item Detalle\_Venta(\underline{\textbf{id\_factura}}, \underline{\textbf{cod\_producto}}, descripcion, unidad, precio)
    \item Medio\_Pago(\textbf{cod\_medio\_pago}, descripcion, valor, unidad, tipo\_operacion)
\end{itemize}

El \emph{script} correspondiente para la definición de las tablas previamente definidas tiene el nombre \textbf{tablas\_sistema\_actual.sql} 

\subsubsection{Poblado}

Los \emph{scripts} realizados para la carga de datos de este sistema son idénticos a los del sistema anterior, adaptándolos a los distintas representaciones de los datos. Para los \textbf{productos} y \textbf{categorías}, también se extrajeron datos de MercadoLibre, agregando como valor de \emph{subcategoría} un valor secuencial entre 1 y 5 por cada categoría (es decir, cada categoria tiene 5 subcategorías secuenciales)

\vspace*{5mm}
\begin{lstlisting}[title=Cantidad de categorías y productos disponibles en el sistema de facturación actual]
facturacion=# SELECT COUNT(*) FROM categoria;
 count 
-------
   150
(1 row)

facturacion=# SELECT COUNT(*) FROM producto;
 count 
-------
  1454
(1 row)
\end{lstlisting}

La carga de \textbf{clientes} es igual (\textbf{sql/clientes.sql}), teniendo en cuenta cargar clientes repetidos para después figuren en las \emph{tablas de equivalencia} del datawarehouse. 

Varios \textbf{medios de pago} fueron registrados mediante el \emph{script} \textbf{sql/medio\_pago.sql}, al igual que \textbf{tipos de cliente} (\textbf{sql/tipo\_cliente.sql})   

Las funciones para creaciones de \textbf{ventas} y \textbf{detalles de ventas} mantienen la misma firma que las implementadas en el sistema viejo (\textbf{sql/venta.sql} y \textbf{sql/detalle\_venta.sql}, respectivamente). 

\vspace*{5mm}
\begin{lstlisting}[title=Inserción de 15 ventas aleatorias en la BD]
facturacion=# SELECT insertar_ventas(15);
NOTICE:  [1/15] INSERTANDO VENTA (2015-07-25, 119357, 252269, Ifeoma G. Collins, Débito)
NOTICE:  [2/15] INSERTANDO VENTA (2014-07-31, 585847, 967234, Keane K. Hodge, Bitcoin)
NOTICE:  [3/15] INSERTANDO VENTA (2013-05-01, 501180, 639678, Edward T. Carey, Crédito)
...
\end{lstlisting}

\vspace*{5mm}
\begin{lstlisting}[title=Inserción de 100 detalles de ventas aleatorias en la BD]
facturacion=# SELECT insertar_detalle_venta(100);
NOTICE:  [1/100] INSERTANDO DETALLE (462363, 678175295, 10, 2249)
NOTICE:  [2/100] INSERTANDO DETALLE (660157, 655324667, 77, 340)
NOTICE:  [3/100] INSERTANDO DETALLE (164479, 612842726, 38, 8499)
...
\end{lstlisting}



\section{Datawarehouse}

\subsection{Marco teórico}

Un Datawarehouse o almacén de datos es definido por \autocite{elmasri-dw} como \emph{una colección de datos orientada al sujeto, integrada, no volátil y de tiempo variable para el soporte de las decisiones de los directivos} 

Existen dos esquemas posibles para la implementación de un datawarehouse. El primero, el \textbf{esquema estrella}, consiste en tener una única \emph{Tabla de Hechos} como objeto central del almacén, y distintas \emph{Tablas de Dimensión} circundantes. La Tabla de Hechos se relaciona con las dimensiones mediante una \emph{clave foránea}, pero las Tablas de Dimesión no se relacionan entre sí.

En este esquema se \dq{desnormalizan} los datos de las bases de datos operacionales de las cuales se nutren el datawarehouse para tener mayor performance (pero con redundancia en los datos)

El otro esquema posible es el \textbf{copo de nieve}. Esta alternativa propone que las Tablas de Dimensión tengan Tablas de Dimesión asociadas a ella. De esta forma, los datos se mantienen normalizados y las relaciones más pequeñas.

Este último esquema es el adecuado para implementar el datawarhouse que requiere \dq{PatSur}.

\subsection{Definición}

\subsection{Poblado}

\subsubsection{\emph{ETL}}


\subsection{Explotación}

Teniendo el datawarhouse creado y con datos cargados a partir de las bases de datos operacionales (luego de convertirlos con los procesos de ETL definidos), se le puede realizar distintas consultas que provean soporte para la toma de decisiones de \dq{PatSur}

\subsection{Distintas perspectivas de las ventas}

Una diferencia vital entre un datawarehouse y una base de datos operativa es la capacidad del primero de soportar operaciones \textbf{OLAP}. El \emph{área de procesamiento analítico en línea} (\emph{Online Analytical Processing}, \emph{OLAP}) trata de las herramientas y de las técnicas para el análisis de los datos que pueden dar respuestas casi instantáneas a las consultas que soliciten datos resumidos, aunque la base de datos (datawarehouse) sea extremedamente grande \autocite{silberschatz-olap}

Para mostrar distintas perspectivas y agrupaciones posibles con respecto a las ventas de la empresa, se puede utilizar una de las extensiones de SQL-1999: la claúsula \textbf{CUBE} 

Debido a la extensión de la consulta, se la puede encontrar en el archivo \textbf{consultas/olap.sql} 

Los siguientes criterios por los cuales se agrupa la cantidad de unidades vendidas y el monto total vendido son:

\begin{itemize}
    \item Fecha
    \item Cliente
    \item Producto
    \item Medio de pago
    \item Sucursal
    \item Ciudad
    \item Provincia
\end{itemize}

Se toma un criterio por vez, y también se agrupa por las distintas combinaciones posibles



\subsection{Clientes que generan mayores ingresos}

La consulta del archivo \textbf{consultas/clientes\_mas\_compradores.sql} utiliza otra extensión de SQL-1999, \textbf{RANK()} para indicar numéricamente un orden de los registros según un criterio indicado  

\vspace*{5mm}
\begin{lstlisting}[title=Clientes que generan mayores ingresos para la empresa]
SELECT 
    cli.id_cliente AS "ID Cliente", 
    cli.nombre AS "Nombre", 
    CAST(SUM(ven.monto_vendido) AS bigint) AS "Total vendido", 
    RANK() OVER (ORDER BY SUM(ven.monto_vendido) DESC) AS "Mayores compradores" 
FROM venta AS ven 
    JOIN cliente AS cli ON ven.id_cliente=cli.id_cliente 
GROUP BY cli.id_cliente;
\end{lstlisting}




\section{Herramienta de \emph{BI}: \emph{Pentaho}}

\emph{Pentaho BI Suite} es un conjunto de programas para el soporte de la toma de decisiones y \emph{Business Intelligence} \autocite{wikipedia-pentaho} de la empresa Hitachi. 

Para este trabajo de laboratorio se utilizaron las herramientas \underline{\href{https://mondrian.pentaho.com/documentation/workbench.php}{\emph{Schema Workbench}}} y \underline{\href{https://help.pentaho.com/Documentation/7.1/Installation}{\emph{BI Server}}} (este último se implementó mediante contenedores de \docker{}, con las configuraciones descriptas en la sección 1)

La herramienta \emph{Schema Worbench} se utilizó para definir el esquema que contiene el cubo OLAP, cuyas medidas y dimensiones son las requeridas por \dq{PatSur}. Estas son:

\begin{itemize}
    \item Medidas:
        \begin{enumerate}
            \item Unidades vendidas
            \item Monto recaudado
        \end{enumerate}
    \item Dimensiones:
        \begin{enumerate}
            \item Fecha
            \item Sucursales
            \item Clientes
            \item Productos
            \item Medios de pago
        \end{enumerate}
\end{itemize}


\subsection*{Integración de \emph{Schema Workbench} con \emph{PostgreSQL}}

Cabe aclarar que para conectarse a una base de datos \emph{PostgreSQL} desde el \emph{Schema Workbench} hace falta descargar los \underline{\href{https://jdbc.postgresql.org/}{drivers JDBC para el motor}} y ubicarlos en el directorio \dq{drivers} dentro del directorio de instalación de \emph{Schema Workbench} 

\subsection{Definición del esquema y del cubo OLAP}

Una vez instalado el driver correspondiente para el motor y con el datawarehouse corriendo, seguir la siguiente secuencia de pasos para poder conectarse a la base de datos y crear el cubo OLAP:

\begin{enumerate}
    \item Crear la conexión con el datawarehouse
    \begin{enumerate}
        \item Hacer click en \texttt{Options}
        \item Seleccionar \texttt{Connection...}
        \item Los datos para la conexión con el datawarehouse son los siguientes:
        \begin{itemize}
            \item Connection Type: PostgreSQL
            \item \textbf{Connection Name}: conn\_datawarehouse 
            \item Host Name: 172.40.0.30
            \item Database Name: datawarehouse
            \item Port Number: 5432
            \item User Name: admin
            \item Password: admin
        \end{itemize}
        \item Hacer click en \texttt{OK}
    \end{enumerate}
    \item Crear un nuevo esquema
    \begin{enumerate}
        \item Hacer click en \texttt{File}
        \item Seleccionar \texttt{New}
        \item Seleccionar \texttt{Schema}
    \end{enumerate}
    \item Crear un nuevo cubo
    \begin{enumerate}
        \item Click derecho sobre el esquema recién creado
        \item Seleccionar \texttt{Add cube}
    \end{enumerate}
    \item Definir la Tabla de Hechos para el cubo
    \begin{enumerate}
        \item Click derecho sobre el cubo
        \item Seleccionar \texttt{Add Table}
    \end{enumerate}
    \item Definir las medidas del cubo
    \begin{enumerate}
        \item Click derecho sobre el cubo
        \item Seleccionar \texttt{Add Measure}
        \item Definir qué columna de la Tabla de Hechos será utilizada como medida y con qué operación (cantidad de valores distintos, suma, cuenta, etc.)
    \end{enumerate}
    \item Definir las dimensiones del cubo
    \begin{enumerate}
        \item Click derecho sobre el cubo
        \item Seleccionar \texttt{Add Dimension}
        \item Cada dimensión tiene una \emph{jerarquía}, la cual debe estar relacionada con una tabla del datawarehouse 
        \item Cada jerarquía también debe tener por lo menos un nivel definido; cada nivel debe estar relacionado con una columna de la tabla de la jerarquía
    \end{enumerate}
    \item Publicar el esquema en el servidor
    \begin{enumerate}
        \item Hacer click en \texttt{File}
        \item Seleccionar \texttt{Publish...}
        \item Los datos que se deben ingresar para publicar el esquema son los siguientes:
        \begin{itemize}
            \item URL: localhost:7070
            \item Credentials:
                \begin{itemize}
                    \item User: admin
                    \item Password: password
                \end{itemize}
        \end{itemize}
        \item Hacer click en \texttt{OK}
    \end{enumerate}
\end{enumerate}

Una vez publicado el esquema en el servidor, navegar a la dirección \emph{localhost:7070} e ingresar las credenciales previamente descriptas (Username: admin, Password: password). 

Antes de visualizar el cubo, se debe crear la conexión con el datawarehouse. Para ello, seguir los siguientes pasos:

\begin{enumerate}
    \item Hacer click en \texttt{Manage Data Sources}
    \item Hacer click en el engranaje
    \item Seleccionar \texttt{New Connection...}
    \item Ingresar \textbf{los mismos datos} con los cuales se definió la conexión al datawarehouse en el \emph{Schema Workbench}   
    \item Volver a la pantalla de inicio
    \item Hacer click en \texttt{Create New}
    \item Seleccionar \texttt{JPivot View} 
    \item Seleccionar el esquema y el cubo adecuado, y hacer click en \texttt{OK} 
\end{enumerate}






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% FIN DOCUMENTO, AHORA REFERENCIAS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\printbibliography

\end{document}

