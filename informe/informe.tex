%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% En 'inclues.tex' se encuentran la importación de paquetes necesarios
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{includes}
\input{listings_settings}


\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% En 'titlepage.tex' se encuentra la página de título
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{titlepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% INDICE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\tableofcontents
\clearpage 

\lstset{style=sql}

\section{Introducción}

Para el siguiente trabajo de laboratorio se solicitaba implementar las bases de datos operacionales y un datawarehouse que satisfaga las necesidades de la empresa \dq{PatSur}. Los requerimientos son los siguientes:

\begin{displayquote}\itshape

La cooperativa frutihorticola “PatSur” lleva operando 5 años en la región patagónica. Ha ido creciendo y abriendo sucursales en otras ciudades y participa en la provisión de mercaderías a fabricas, otras cooperativas, pymes, cadenas de supermercados. A medida que fue ampliando su ámbito de compra y venta ha ido modifcando sus sistemas para manejar nuevos datos como producciones, vendedores y compradores, lugares de compra y venta, transportes, empleados, etc. De allí que cada Gerente de área posea distintos datos en diferentes formas. Por lo tanto la primer idea es tener un información de las ventas. 

La empresa cuenta con dos (2) sistemas distintos de facturación de productos (a partir del año 2010 se implementó un sistema desarrollado por una consultora, mientras que antes del 2010 se utilizaba un sistema desarrollado por el sobrino de uno de los socios de la cooperativa).  

\end{displayquote}

Las implementaciones de todos los sistemas necesarios fueron hechas con contenedores de \docker{} y orquestrados con \doccom{}; se deja a disposición con el presente informe y todos los \emph{scripts} utilizados el archivo de configuración para levantar todos los contenedores necesarios. 

Los cuatro servicios creados por contenedores (un contenedor por servicio) se encuentran dentro de la red \textbf{172.40.0.0/16}, cada uno con las siguientes características:
\begin{itemize}
    \item Sistema de facturación viejo:
        \begin{itemize}
            \item Imagen: \underline{\href{https://hub.docker.com/_/postgres/}{PostgreSQL 9.6}}
            \item Dirección IP: 172.40.0.10
            \item Puerto de escucha: 5432
            \item Nombre de la base de datos: facturacion
            \item Usuario: admin
            \item Contraseña: admin
        \end{itemize}
    \item Sistema de facturación actual
        \begin{itemize}
            \item Imagen: \underline{\href{https://hub.docker.com/_/postgres/}{PostgreSQL 9.6}}
            \item Dirección IP: 172.40.0.20
            \item Puerto de escucha: 5432
            \item Nombre de la base de datos: facturacion
            \item Usuario: admin
            \item Contraseña: admin
        \end{itemize}
    \item Datawarehouse:
        \begin{itemize}
            \item Imagen: \underline{\href{https://hub.docker.com/_/postgres/}{PostgreSQL 9.6}}
            \item Dirección IP: 172.40.0.30
            \item Puerto de escucha: 5432
            \item Nombre de la base de datos: datawarehouse
            \item Usuario: admin
            \item Contraseña: admin
        \end{itemize}
    \item Pentaho \emph{BI Server} :
        \begin{itemize}
            \item Imagen: \underline{\href{https://hub.docker.com/r/wmarinho/pentaho/}{Pentaho BI Server}}
            \item Dirección IP: 172.40.0.40
            \item Puerto de escucha: 7070
        \end{itemize}
\end{itemize}

\section{Bases de datos operacionales}

Los sistemas de facturación de \dq{PatSur} presentan distintos modelados de datos, por lo cual la definición de las tablas de las bases de datos y su correspondiente cargado de datos serán procesos distintos.

Todos los \emph{scipts} a los que se haga referencia se encontrarán en el directorio \textbf{\dq{scripts}}. Los \emph{scripts} correspondientes a la carga de datos tanto de los sistemas operacionales como del datawarehouse se encontrarán en el subdirectorio \textbf{\dq{scripts/cargas}}   

\subsection{Sistema viejo}

\subsubsection{Definición}

El primer sistema con el que dispuso la empresa tenía la siguiente estructura de tablas:

\begin{itemize}
    \item Cliente(\textbf{nro\_cliente}, nombre, tipo, direccion)
    \item Categoria(\textbf{nro\_categ}, descripcion)
    \item Venta(\textbf{nro\_factura}, fecha\_venta, \underline{nro\_cliente}, nombre, forma\_pago)
    \item Detalle\_Venta(\underline{\textbf{nro\_factura}}, \underline{\textbf{nro\_producto}}, descripcion, unidad, precio)
    \item Producto(\textbf{nro\_producto}, nombre, \underline{nro\_categ}, precio\_actual)
\end{itemize}

El \emph{script} correspondiente para la definición de las tablas previamente definidas tiene el nombre \textbf{tablas\_sistema\_viejo.sql} 

\subsubsection{Poblado}

\emph{Los siguientes \emph{scripts} mencionados se encuentran en el subdirectorio \dq{scripts/cargas/sistema\_viejo} y en \dq{scripts/cargas/sistema\_viejo/sql}} 

~\\

A través de \emph{scripts} escritos en Python (\textbf{productos.py} y \textbf{categorias.py}), se pudieron extraer datos de la \emph{API} de MercadoLibre \autocite{api} para disponer de datos con cierto grado de veracidad. Estos \emph{scripts} se encargan de consultar la fuente de datos, y de armar \emph{scripts} en SQL (\textbf{sql/productos} y \textbf{categorias.sql}) para la inserción en la tabla correspondiente (adecuando los datos acordemente al modelo de la base de datos)  

MercadoLibre maneja un árbol de \textbf{categorías} muy amplio y con muchas ramas, de las cuales solamente se exploraron y utilizaron unas pocas para este trabajo. También se obtuvieron \textbf{productos} de dichas categorías

\vspace*{5mm}
\begin{lstlisting}[title=Cantidad de categorías y productos disponibles en el sistema de facturación viejo]
facturacion=# SELECT COUNT(*) FROM categoria;
 count 
-------
    30
(1 row)

facturacion=# SELECT COUNT(*) FROM producto;
 count 
-------
  1450
(1 row)
\end{lstlisting}

Con respecto a los \textbf{clientes}, se utilizó un sitio generador de datos \autocite{data} para crear registros de clientes ficticios (\textbf{sql/clientes.sql}). 

Por último, los archivos \textbf{sql/venta.sql} y \textbf{sql/detalle\_venta.sql} contienen las definiciones de las funciones \textbf{insertar\_venta(int)} e \textbf{insertar\_detalle\_venta(int)}. Ambas funciones reciben un valor entero como parámetro, que indica la cantidad de registros que se quieren crear (tomando valores aleatorios de la base). Estas funciones son acumulativas, entonces se pueden correr cuantas veces se desee para poblar las tablas de ventas y detalles de ventas.

\vspace*{5mm}
\begin{lstlisting}[title=Inserción de 50 ventas aleatorias en la BD]
facturacion=# SELECT insertar_ventas(50);
NOTICE:  [1/50] INSERTANDO VENTA (2007-10-03, 862512, 4118, Linda Acosta, EFECTIVO)
NOTICE:  [2/50] INSERTANDO VENTA (2002-07-29, 143370, 3458, Jeremy Pacheco, CREDITO)
NOTICE:  [3/50] INSERTANDO VENTA (2006-02-15, 993978, 2414, Lisandra Bernard, DEBITO)
...
\end{lstlisting}

\vspace*{5mm}
\begin{lstlisting}[title=Inserción de 300 detalles de ventas aleatorias en la BD]
facturacion=# SELECT insertar_detalle_venta(300);
NOTICE:  [1/300] INSERTANDO DETALLE (333538, 639930615, 19, 169.99)
NOTICE:  [2/300] INSERTANDO DETALLE (743695, 644739590, 41, 72)
NOTICE:  [3/300] INSERTANDO DETALLE (124334, 712205536, 54, 419500)
...
\end{lstlisting}

\subsection{Sistema actual}

\subsubsection{Definición}

El sistema desarrollado en el 2010 por la consultora cuenta con el siguiente esquema:

\begin{itemize}
    \item Cliente(\textbf{cod\_cliente}, nombre, \underline{cod\_tipo}, direccion)
    \item Tipo\_Cliente(\textbf{cod\_tipo}, descripcion)
    \item Producto(\textbf{cod\_producto}, nombre, \underline{cod\_categoria}, \underline{cod\_subcategoria}, precio\_actual)
    \item Categoria(\textbf{cod\_categoria}, \textbf{cod\_subcategoria}, descripcion)
    \item Venta(\textbf{id\_factura}, fecha\_venta, \underline{cod\_cliente}, nombre, \underline{cod\_medio\_pago})
    \item Detalle\_Venta(\underline{\textbf{id\_factura}}, \underline{\textbf{cod\_producto}}, descripcion, unidad, precio)
    \item Medio\_Pago(\textbf{cod\_medio\_pago}, descripcion, valor, unidad, tipo\_operacion)
\end{itemize}

El \emph{script} correspondiente para la definición de las tablas previamente definidas tiene el nombre \textbf{tablas\_sistema\_actual.sql} 

\subsubsection{Poblado}

Los \emph{scripts} realizados para la carga de datos de este sistema son idénticos a los del sistema anterior, adaptándolos a los distintas representaciones de los datos. Para los \textbf{productos} y \textbf{categorías}, también se extrajeron datos de MercadoLibre, agregando como valor de \emph{subcategoría} un valor secuencial entre 1 y 5 por cada categoría (es decir, cada categoria tiene 5 subcategorías secuenciales)

\vspace*{5mm}
\begin{lstlisting}[title=Cantidad de categorías y productos disponibles en el sistema de facturación actual]
facturacion=# SELECT COUNT(*) FROM categoria;
 count 
-------
   150
(1 row)

facturacion=# SELECT COUNT(*) FROM producto;
 count 
-------
  1454
(1 row)
\end{lstlisting}

La carga de \textbf{clientes} es igual (\textbf{sql/clientes.sql}), teniendo en cuenta cargar clientes repetidos para después figuren en las \emph{tablas de equivalencia} del datawarehouse. 

Varios \textbf{medios de pago} fueron registrados mediante el \emph{script} \textbf{sql/medio\_pago.sql}, al igual que \textbf{tipos de cliente} (\textbf{sql/tipo\_cliente.sql})   

Las funciones para creaciones de \textbf{ventas} y \textbf{detalles de ventas} mantienen la misma firma que las implementadas en el sistema viejo (\textbf{sql/venta.sql} y \textbf{sql/detalle\_venta.sql}, respectivamente). 

\vspace*{5mm}
\begin{lstlisting}[title=Inserción de 15 ventas aleatorias en la BD]
facturacion=# SELECT insertar_ventas(15);
NOTICE:  [1/15] INSERTANDO VENTA (2015-07-25, 119357, 252269, Ifeoma G. Collins, Débito)
NOTICE:  [2/15] INSERTANDO VENTA (2014-07-31, 585847, 967234, Keane K. Hodge, Bitcoin)
NOTICE:  [3/15] INSERTANDO VENTA (2013-05-01, 501180, 639678, Edward T. Carey, Crédito)
...
\end{lstlisting}

\vspace*{5mm}
\begin{lstlisting}[title=Inserción de 100 detalles de ventas aleatorias en la BD]
facturacion=# SELECT insertar_detalle_venta(100);
NOTICE:  [1/100] INSERTANDO DETALLE (462363, 678175295, 10, 2249)
NOTICE:  [2/100] INSERTANDO DETALLE (660157, 655324667, 77, 340)
NOTICE:  [3/100] INSERTANDO DETALLE (164479, 612842726, 38, 8499)
...
\end{lstlisting}



\section{Datawarehouse}

\subsection{Marco teórico}

Un Datawarehouse o almacén de datos es definido por \autocite{elmasri-dw} como \emph{una colección de datos orientada al sujeto, integrada, no volátil y de tiempo variable para el soporte de las decisiones de los directivos} 

Existen dos esquemas posibles para la implementación de un datawarehouse. El primero, el \textbf{esquema estrella}, consiste en tener una única \emph{Tabla de Hechos} como objeto central del almacén, y distintas \emph{Tablas de Dimensión} circundantes. La Tabla de Hechos se relaciona con las dimensiones mediante una \emph{clave foránea}, pero las Tablas de Dimesión no se relacionan entre sí.

En este esquema se \dq{desnormalizan} los datos de las bases de datos operacionales de las cuales se nutren el datawarehouse para tener mayor performance (pero con redundancia en los datos)

El otro esquema posible es el \textbf{copo de nieve}. Esta alternativa propone que las Tablas de Dimensión tengan Tablas de Dimesión asociadas a ella. De esta forma, los datos se mantienen normalizados y las relaciones más pequeñas.

Este último esquema es el adecuado para implementar el datawarhouse que requiere \dq{PatSur}.

\subsection{Definición}

Se utilizó la siguiente estructura de tablas.

\begin{itemize}
    \item Categoria(\textbf{id\_categoria}, \textbf{id\_subcategoria}, descripcion)
    \item Producto(\textbf{id\_producto}, \underline{id\_categoria}, \underline{id\_subcategoria}, descripcion)
    \item Medios(\textbf{id\_medio\_pago}, descripcion)
    \item Region(\textbf{id\_region}, descripcion)
    \item Provincia(\textbf{id\_provincia}, \underline{id\_region}, descripcion)
    \item Ciudad(\textbf{id\_ciudad}, \underline{id\_provincia}, descripcion)
    \item DistribucionGeografica(\textbf{id\_sucursal}, \underline{id\_ciudad}, descripcion)
    \item TipoCliente(\textbf{id\_tipo}, descripcion)
    \item Cliente(\textbf{id\_cliente}, \underline{id\_tipo}, nombre)
    \item Tiempo(\textbf{id\_tiempo}, anio, mes)
    \item Venta(fecha, \underline{\textbf{id\_tiempo}}, \underline{\textbf{id\_factura}}, \underline{\textbf{id\_cliente}}, \underline{\textbf{id\_producto}}, \underline{\textbf{id\_sucursal}}, \underline{\textbf{id\_medio\_pago}}, monto\_vendido, cantidad\_vendida, descripcion)
\end{itemize}

\subsection{Poblado}

Todos los \emph{scripts} mencionados a continuación se pueden encontrar en el subdirectorio \textbf{scripts/cargas/datawarehouse}

Para poder relizar la integración de los datos se decidió utilizar tablas de equivalencia para las tablas Producto y Cliente de ambos sistemas de facturación.

Se utilizó la siguiente estructura:

\begin{itemize}
    \item TECliente(cliente\_s\_v, cliente\_s\_n, cliente\_d\_w)
    \item TEProducto(producto\_s\_v, producto\_s\_n, producto\_d\_w)
\end{itemize}

Para las tablas de categoría, región, provincia, ciudad, sucursal, medio de pago y tipo de cliente se utilizaron los mismos datos en ambos sistemas o se fabricaron datos para poner en el datawarehouse.

Luego se implementaron los scripts para que, desde el datawarehouse, se realicen una consultas remotas a los sistemas nuevo y viejo, se realizara la equivalencia y se insertaran en las tablas de equivalencia. Detallado a continuacion. 

\begin{lstlisting}[title=Inserción a la tabla de equivalencia de cliente]

-- Conexión con el sistema de facturación viejo
SELECT DBLINK_CONNECT(
	'sistema_viejo',
	'host=172.40.0.10 port=5432 password=admin user=admin dbname=facturacion'
);

-- Conexión con el sistema actual
SELECT DBLINK_CONNECT(
	'sistema_actual',
	'host=172.40.0.20 port=5432 password=admin user=admin dbname=facturacion'
);

-- Inserta en la tabla de equivalencia de clientes
-- teniendo en cuenta que pueden haber clientes con el mismo nombre,
-- en cuyo caso los inserta en la misma fila

INSERT INTO te_cliente (cliente_s_n, cliente_s_v)
SELECT
    consulta_actual.cod_cliente,
    consulta_viejo.nro_cliente
FROM
    DBLINK('sistema_actual', 'SELECT cod_cliente, nombre FROM cliente')
    AS consulta_actual(cod_cliente integer, nombre varchar(50))
    FULL OUTER JOIN
        DBLINK('sistema_viejo', 'select nro_cliente, nombre from cliente')
        AS consulta_viejo(nro_cliente integer, nombre varchar(50))
    ON consulta_viejo.nombre = consulta_actual.nombre;
    
\end{lstlisting}

Para la inserción en la tabla de equivalencia de \textbf{productos} el procedimiento es similar, considerando el nombre de los productos.

Los scripts se pueden encontrar en \textbf{te\_cliente.sql} y \textbf{te\_producto.sql}

Se corren ambos scripts y ya tenemos a nuestra disposición las tablas de equivalencia para relizar el \textbf{ETL}.

Con respecto al resto de las tablas, se utilizan los scripts homónimos a las tablas a poblar. Por ejemplo: \textbf{categoria.sql}, \textbf{region.sql}


\subsubsection{\emph{ETL}}

Para el etl se crea una tabla temporal en la cual albergar las ventas para un mes y año determinados, y desde aquí realizar las inserciones a las tablasd de Cliente, Producto, Venta y Tiempo. Este procedimiento realizado a través de una función a la cual se le pasa el mes y año a insertar en el \emph{Datawarehouse}

La creación de la tabla temporal, dentro de la función se realiza de la siguiente manera:

\begin{lstlisting}[title=Creación de la Tabla Temporal]
-- Conexión con el sitio del cual conseguir los datos
PERFORM DBLINK_CONNECT(
    'sistema_actual',
    'host=172.40.0.20 port=5432 password=admin user=admin dbname=facturacion'
);

-- Creación tabla tempora
create table tmp_ventas as
select
* 
from 
dblink(
    'sistema_actual', 
    'select
    fecha_venta,
    v.id_factura,
    v.cod_cliente,
    dv.cod_producto,
    cod_medio_pago,
    unidad * precio as monto_vendido,
    unidad as cantidad_vendida,
    p.nombre as nombre_producto,
    p.cod_categoria,
    p.cod_subcategoria,
    precio,
    c.nombre as nombre_cliente,
    c.cod_tipo
    from venta v, cliente c, detalle_venta dv, producto p
    where 
    v.id_factura = dv.id_factura
    and v.cod_cliente = c.cod_cliente
    and dv.cod_producto = p.cod_producto 
    and date_part ( ''month'',   fecha_venta) =  '|| $2 ||'
            and date_part (''year'',  fecha_venta) = ' || $1 ||'
    order by 1'
) as st(
    fecha_venta date,
    id_factura integer,
    cod_cliente integer,
    cod_producto integer,
    cod_medio_pago integer,
    monto_vendido real,
    cantidad_vendida integer,
    nombre_producto varchar(100),
    cod_categoria integer,
    cod_subcategoria integer,
    precio real,
    nombre_cliente varchar(100),
    cod_tipo integer
);
\end{lstlisting}

La selección y de datos y el armado de la tabla temporal considera la estructura del sitio del cual extrae los datos, lo cual hace que los campos que selecciona no sean los mismos cuando se extrae del sistema nuevo que cuando se extrae del sistema nuevo. Luego se realizan las inserciones a Producto, Cliente y Venta desde la tabla temporal. Una vez realizada la inserción, se realiza un drop de la tabla.


\emph{Ambos manejos ETL están en los \emph{scripts} \textbf{poblar\_dw\_sistema\_viejo.sql} y \textbf{poblar\_dw\_sistema\_nuevo.sql}.}

Para facilitar la utilización del \emph{Datawarehouse} por parte de la Herramienta de BI se generaron vistas que reduzcan el esquema de Copo de Nieve planteado a uno de Estrella. Esta definción se encuentra en el archivo \textbf{src/vistas\_datawarehouse.sql}

\subsection{Explotación}

Teniendo el datawarhouse creado y con datos cargados a partir de las bases de datos operacionales (luego de convertirlos con los procesos de ETL definidos), se le puede realizar distintas consultas que provean soporte para la toma de decisiones de \dq{PatSur}

\subsection{Distintas perspectivas de las ventas}

Una diferencia vital entre un datawarehouse y una base de datos operativa es la capacidad del primero de soportar operaciones \textbf{OLAP}. El \emph{área de procesamiento analítico en línea} (\emph{Online Analytical Processing}, \emph{OLAP}) trata de las herramientas y de las técnicas para el análisis de los datos que pueden dar respuestas casi instantáneas a las consultas que soliciten datos resumidos, aunque la base de datos (datawarehouse) sea extremedamente grande \autocite{silberschatz-olap}

Para mostrar distintas perspectivas y agrupaciones posibles con respecto a las ventas de la empresa, se puede utilizar una de las extensiones de SQL-1999: la claúsula \textbf{CUBE} 

Debido a la extensión de la consulta, se la puede encontrar en el archivo \textbf{consultas/olap.sql} 

Los siguientes criterios por los cuales se agrupa la cantidad de unidades vendidas y el monto total vendido son:

\begin{itemize}
    \item Fecha
    \item Cliente
    \item Producto
    \item Medio de pago
    \item Sucursal
    \item Ciudad
    \item Provincia
\end{itemize}

Se toma un criterio por vez, y también se agrupa por las distintas combinaciones posibles



\subsection{Clientes que generan mayores ingresos}

La consulta del archivo \textbf{consultas/clientes\_mas\_compradores.sql} utiliza otra extensión de SQL-1999, \textbf{RANK()} para indicar numéricamente un orden de los registros según un criterio indicado  

\vspace*{5mm}
\begin{lstlisting}[title=Clientes que generan mayores ingresos para la empresa]
SELECT 
    cli.id_cliente AS "ID Cliente", 
    cli.nombre AS "Nombre", 
    CAST(SUM(ven.monto_vendido) AS bigint) AS "Total vendido", 
    RANK() OVER (ORDER BY SUM(ven.monto_vendido) DESC) AS "Mayores compradores" 
FROM venta AS ven 
    JOIN cliente AS cli ON ven.id_cliente=cli.id_cliente 
GROUP BY cli.id_cliente;
\end{lstlisting}




\section{Herramienta de \emph{BI}: \emph{Pentaho}}






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% FIN DOCUMENTO, AHORA REFERENCIAS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\printbibliography

\end{document}

